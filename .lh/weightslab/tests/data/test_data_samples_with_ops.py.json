{
    "sourceFile": "weightslab/tests/data/test_data_samples_with_ops.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1771952261922,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1771952318398,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -519,9 +519,9 @@\n         )\r\n \r\n         # Get sample ID at index 0\r\n         sample_id = wrapper.get_sample_id_at_index(0)\r\n-        self.assertEqual(sample_id, int(wrapper.unique_ids[0]))\r\n+        self.assertEqual(sample_id, wrapper.unique_ids[0])\r\n \r\n     def test_get_index_from_sample_id(self):\r\n         \"\"\"Test retrieving index from sample ID.\"\"\"\r\n \r\n@@ -532,9 +532,9 @@\n             compute_hash=False,\r\n         )\r\n \r\n         # Get index from first sample ID\r\n-        sample_id = int(wrapper.unique_ids[0])\r\n+        sample_id = wrapper.unique_ids[0]\r\n         index = wrapper.get_index_from_sample_id(sample_id)\r\n         self.assertEqual(index, 0)\r\n \r\n     def test_infer_num_classes_from_dataset(self):\r\n"
                },
                {
                    "date": 1771952731609,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -299,9 +299,8 @@\n             tags_mapping=tags_mapping,\r\n         )\r\n \r\n         sample_id_0 = wrapper.unique_ids[0]\r\n-        sample_id_1 = wrapper.unique_ids[1]\r\n \r\n         # Set target_tag on sample 0\r\n         wrapper.set(sample_id=sample_id_0, stat_name=\"tags\", value='target_tag')\r\n \r\n"
                }
            ],
            "date": 1771952261922,
            "name": "Commit-0",
            "content": "\"\"\"\r\nUnit tests for data_samples_with_ops.py\r\n\r\nTests the DataSampleTrackingWrapper class, which wraps PyTorch datasets\r\nand provides per-sample statistics tracking and tag-based labeling.\r\n\"\"\"\r\n\r\nimport os\r\nimport tempfile\r\nimport unittest\r\nimport numpy as np\r\nimport torch\r\n\r\nimport weightslab as wl\r\n\r\nfrom torch.utils.data import Dataset\r\nfrom unittest.mock import patch\r\n\r\nfrom weightslab.data.data_samples_with_ops import (\r\n    DataSampleTrackingWrapper,\r\n    _has_regex_symbols,\r\n    _match_column_patterns,\r\n    _filter_columns_with_patterns,\r\n)\r\n\r\n\r\nclass SimpleDataset(Dataset):\r\n    \"\"\"Simple dataset for testing.\"\"\"\r\n\r\n    def __init__(self, size=10):\r\n        self.size = size\r\n        self.__name__ = \"simple_dataset\"\r\n\r\n    def __len__(self):\r\n        return self.size\r\n\r\n    def __getitem__(self, idx):\r\n        # Return random data with shape (3, 32, 32) to simulate images\r\n        data = np.random.randn(3, 32, 32).astype(np.float32)\r\n        uid = np.random.randn(1)\r\n        label = idx % 10  # Simulate 10 classes\r\n        return data, uid, label\r\n\r\n\r\nclass TestHelperFunctions(unittest.TestCase):\r\n    \"\"\"Test helper utility functions.\"\"\"\r\n\r\n    def test_has_regex_symbols(self):\r\n        \"\"\"Test regex symbol detection.\"\"\"\r\n        # True cases\r\n        self.assertTrue(_has_regex_symbols(\".*\"))\r\n        self.assertTrue(_has_regex_symbols(\"test.*\"))\r\n        self.assertTrue(_has_regex_symbols(\"[abc]\"))\r\n        self.assertTrue(_has_regex_symbols(\"(test)\"))\r\n        self.assertTrue(_has_regex_symbols(\"test+\"))\r\n\r\n        # False cases\r\n        self.assertFalse(_has_regex_symbols(\"test\"))\r\n        self.assertFalse(_has_regex_symbols(\"test_column\"))\r\n        self.assertFalse(_has_regex_symbols(\"123\"))\r\n\r\n    def test_match_column_patterns(self):\r\n        \"\"\"Test column pattern matching.\"\"\"\r\n        # Exact match\r\n        self.assertTrue(_match_column_patterns(\"test_col\", [\"test_col\"]))\r\n        self.assertTrue(_match_column_patterns(\"exact\", [\"exact\", \"other\"]))\r\n\r\n        # Regex match\r\n        self.assertTrue(_match_column_patterns(\"test_1\", [\"test_.*\"]))\r\n        self.assertTrue(_match_column_patterns(\"feature_loss\", [\".*_loss\"]))\r\n\r\n        # No match\r\n        self.assertFalse(_match_column_patterns(\"column\", [\"other\"]))\r\n        self.assertFalse(_match_column_patterns(\"test\", [\".*_loss\"]))\r\n\r\n    def test_filter_columns_with_patterns(self):\r\n        \"\"\"Test column filtering by patterns.\"\"\"\r\n        columns = [\"loss\", \"loss_train\", \"accuracy\", \"test_accuracy\", \"feature_map\"]\r\n\r\n        # Exact patterns\r\n        result = _filter_columns_with_patterns(columns, [\"loss\"])\r\n        self.assertEqual(result, [\"loss\"])\r\n\r\n        # Regex patterns - note: the regex is correctly anchored, so \".*accuracy\" matches \"accuracy\" and \"test_accuracy\"\r\n        result = _filter_columns_with_patterns(columns, [\".*accuracy\"])\r\n        self.assertIn(\"accuracy\", result)\r\n        self.assertIn(\"test_accuracy\", result)\r\n\r\n        # Multiple patterns - \"loss\" and \"accuracy\" should match \"loss\", \"accuracy\", \"test_accuracy\" = 2 matches (not 3 - loss_train is separate)\r\n        result = _filter_columns_with_patterns(columns, [\"loss\", \"accuracy\"])\r\n        # \"loss\" matches exactly \"loss\" (1), \"accuracy\" matches \"accuracy\" and \"test_accuracy\" (2) = 2 total\r\n        self.assertGreaterEqual(len(result), 2)\r\n\r\n        # Empty result\r\n        result = _filter_columns_with_patterns(columns, [\"nonexistent\"])\r\n        self.assertEqual(result, [])\r\n\r\n\r\nclass TestDataSampleTrackingWrapperInit(unittest.TestCase):\r\n    \"\"\"Test initialization and basic properties.\"\"\"\r\n\r\n    def setUp(self):\r\n        \"\"\"Create a temporary directory for logs.\"\"\"\r\n        self.temp_dir = tempfile.mkdtemp()\r\n        self.dataset = SimpleDataset(size=10)\r\n\r\n        # Initialize HP\r\n        parameters = {\r\n            'flush_interval': 3.0,\r\n            'flush_max_rows': 100,\r\n            'enable_h5': True,\r\n            'enable_flush': True\r\n        }\r\n        wl.watch_or_edit(\r\n            parameters,\r\n            flag=\"hyperparameters\",\r\n            defaults=parameters,\r\n            poll_interval=1.0,\r\n        )\r\n\r\n    def tearDown(self):\r\n        \"\"\"Clean up temporary files.\"\"\"\r\n        import shutil\r\n        if os.path.exists(self.temp_dir):\r\n            shutil.rmtree(self.temp_dir)\r\n\r\n    def test_initialization_with_valid_params(self):\r\n        \"\"\"Test wrapper initialization with valid parameters.\"\"\"\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            is_training=True,\r\n            loader_name=\"train\",\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        self.assertEqual(len(wrapper), len(self.dataset))\r\n        self.assertEqual(wrapper.loader_name, \"train\")\r\n        self.assertTrue(wrapper.is_training)\r\n        self.assertIsNotNone(wrapper.unique_ids)\r\n\r\n    def test_length_matches_dataset(self):\r\n        \"\"\"Test that wrapper length matches dataset length.\"\"\"\r\n\r\n        dataset_size = 20\r\n        dataset = SimpleDataset(size=dataset_size)\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        self.assertEqual(len(wrapper), dataset_size)\r\n\r\n\r\nclass TestDataSampleTrackingWrapperGetItem(unittest.TestCase):\r\n    \"\"\"Test __getitem__ and data retrieval.\"\"\"\r\n\r\n    def setUp(self):\r\n        \"\"\"Create a temporary directory for logs.\"\"\"\r\n        self.temp_dir = tempfile.mkdtemp()\r\n        self.dataset = SimpleDataset(size=10)\r\n\r\n        # Initialize HP\r\n        parameters = {\r\n            'flush_interval': 3.0,\r\n            'flush_max_rows': 100,\r\n            'enable_h5': True,\r\n            'enable_flush': True\r\n        }\r\n        wl.watch_or_edit(\r\n            parameters,\r\n            flag=\"hyperparameters\",\r\n            defaults=parameters,\r\n            poll_interval=1.0,\r\n        )\r\n\r\n    def tearDown(self):\r\n        \"\"\"Clean up temporary files.\"\"\"\r\n        import shutil\r\n        if os.path.exists(self.temp_dir):\r\n            shutil.rmtree(self.temp_dir)\r\n\r\n    def test_getitem_returns_data_and_id(self):\r\n        \"\"\"Test that __getitem__ returns (data, id, label, ...).\"\"\"\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n            use_tags=False,\r\n        )\r\n\r\n        # Get first item\r\n        result = wrapper[0]\r\n\r\n        # Should return tuple with (data, id, target, ...)\r\n        self.assertIsInstance(result, tuple)\r\n        self.assertGreaterEqual(len(result), 3)  # data, id, target at minimum\r\n\r\n        # First element should be numpy array or tensor\r\n        self.assertTrue(isinstance(result[0], (np.ndarray, torch.Tensor)))\r\n\r\n        # Second element should be a numeric UID\r\n        self.assertTrue(isinstance(result[1], (str, int)))\r\n\r\n\r\nclass TestDataSampleTrackingWrapperTagBasedLabeling(unittest.TestCase):\r\n    \"\"\"Test tag-based labeling functionality.\"\"\"\r\n\r\n    def setUp(self):\r\n        \"\"\"Create a temporary directory for logs.\"\"\"\r\n        self.temp_dir = tempfile.mkdtemp()\r\n        self.dataset = SimpleDataset(size=10)\r\n\r\n        # Initialize HP\r\n        parameters = {\r\n            'flush_interval': 3.0,\r\n            'flush_max_rows': 100,\r\n            'enable_h5': True,\r\n            'enable_flush': True\r\n        }\r\n        wl.watch_or_edit(\r\n            parameters,\r\n            flag=\"hyperparameters\",\r\n            defaults=parameters,\r\n            poll_interval=1.0,\r\n        )\r\n\r\n    def tearDown(self):\r\n        \"\"\"Clean up temporary files.\"\"\"\r\n        import shutil\r\n        if os.path.exists(self.temp_dir):\r\n            shutil.rmtree(self.temp_dir)\r\n\r\n    def test_binary_tag_labeling(self):\r\n        \"\"\"Test tag-based labeling with individual boolean tag columns.\r\n        \r\n        Tags are now stored as individual boolean columns (tags_tagname) instead of\r\n        a single comma-separated string. This test verifies that tagging creates the\r\n        appropriate columns and that the tags are correctly stored and retrieved.\r\n        \"\"\"\r\n\r\n        tags_mapping = {\"target_tag\": 1, \"non_target_tag\": 0}\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n            use_tags=True,\r\n            tags_mapping=tags_mapping,\r\n        )\r\n\r\n        # Get sample IDs\r\n        sample_id_0 = wrapper.unique_ids[0]\r\n        sample_id_1 = wrapper.unique_ids[1]\r\n\r\n        # Verify no tag columns exist initially\r\n        df = wrapper.get_dataframe()\r\n        tag_columns_before = [col for col in df.columns if col.startswith(\"tag:\")]\r\n        self.assertEqual(len(tag_columns_before), 0, \"No tag columns should exist initially\")\r\n\r\n        # Set target_tag for first sample\r\n        wrapper.set(sample_id=sample_id_0, stat_name=\"tags\", value='target_tag')\r\n        \r\n        # Verify tag column was created\r\n        df = wrapper.get_dataframe()\r\n        self.assertIn('tag:target_tag', df.columns, \"tag:target_tag column should exist\")\r\n        self.assertEqual(df.loc[sample_id_0, 'tag:target_tag'], 1, \"target_tag should be set to 1\")\r\n\r\n        # Set non_target_tag for second sample\r\n        wrapper.set(sample_id=sample_id_1, stat_name=\"tags\", value='non_target_tag')\r\n\r\n        # Verify both tag columns exist\r\n        df = wrapper.get_dataframe()\r\n        self.assertIn('tag:target_tag', df.columns)\r\n        self.assertIn('tag:non_target_tag', df.columns)\r\n        self.assertEqual(df.loc[sample_id_1, 'tag:non_target_tag'], 1)\r\n\r\n    def test_binary_tag_labeling_single_tag(self):\r\n        \"\"\"Test binary tag-based labeling with a single target tag.\r\n        \r\n        When tags_mapping has only 1 tag, it's binary classification:\r\n        - tag matches → 1\r\n        - tag doesn't match (or no tags) → 0\r\n        \"\"\"\r\n\r\n        tags_mapping = {\"target_tag\": 1}  # Binary: only 1 tag in mapping\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n            use_tags=True,\r\n            tags_mapping=tags_mapping,\r\n        )\r\n\r\n        sample_id_0 = wrapper.unique_ids[0]\r\n        sample_id_1 = wrapper.unique_ids[1]\r\n\r\n        # Set target_tag on sample 0\r\n        wrapper.set(sample_id=sample_id_0, stat_name=\"tags\", value='target_tag')\r\n\r\n        # Verify tags were set  \r\n        df = wrapper.get_dataframe()\r\n        self.assertIn('tag:target_tag', df.columns)\r\n        self.assertEqual(df.loc[sample_id_0, 'tag:target_tag'], 1)\r\n\r\n    def test_tag_parsing_comma_and_semicolon(self):\r\n        \"\"\"Test that tags can be separated by commas, semicolons, or both.\r\n        \r\n        The tag parsing should handle:\r\n        - \"tag1,tag2,tag3\" → creates tag:tag1, tag:tag2, tag:tag3\r\n        - \"tag1;tag2;tag3\" → creates tag:tag1, tag:tag2, tag:tag3\r\n        - \"tag1, tag2; tag3\" → creates tag:tag1, tag:tag2, tag:tag3 (trims whitespace)\r\n        \"\"\"\r\n\r\n        tags_mapping = {\"tag1\": 1, \"tag2\": 2, \"tag3\": 3}\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n            use_tags=True,\r\n            tags_mapping=tags_mapping,\r\n        )\r\n\r\n        sample_id = wrapper.unique_ids[0]\r\n\r\n        # Test comma-separated tags\r\n        wrapper.set(sample_id=sample_id, stat_name=\"tags\", value='tag1,tag2,tag3')\r\n        df = wrapper.get_dataframe()\r\n        self.assertEqual(df.loc[sample_id, 'tag:tag1'], 1)\r\n        self.assertEqual(df.loc[sample_id, 'tag:tag2'], 1)\r\n        self.assertEqual(df.loc[sample_id, 'tag:tag3'], 1)\r\n\r\n        # Test semicolon-separated tags on different sample\r\n        sample_id_2 = wrapper.unique_ids[2]\r\n        wrapper.set(sample_id=sample_id_2, stat_name=\"tags\", value='tag1;tag2;tag3')\r\n        df = wrapper.get_dataframe()\r\n        self.assertEqual(df.loc[sample_id_2, 'tag:tag1'], 1)\r\n        self.assertEqual(df.loc[sample_id_2, 'tag:tag2'], 1)\r\n        self.assertEqual(df.loc[sample_id_2, 'tag:tag3'], 1)\r\n\r\nclass TestDataSampleTrackingWrapperDenylist(unittest.TestCase):\r\n    \"\"\"Test denylisting and allowlisting functionality.\"\"\"\r\n\r\n    def setUp(self):\r\n        \"\"\"Create a temporary directory for logs.\"\"\"\r\n        self.temp_dir = tempfile.mkdtemp()\r\n        self.dataset = SimpleDataset(size=10)\r\n\r\n        # Initialize HP\r\n        parameters = {\r\n            'flush_interval': 3.0,\r\n            'flush_max_rows': 100,\r\n            'enable_h5': True,\r\n            'enable_flush': True\r\n        }\r\n        wl.watch_or_edit(\r\n            parameters,\r\n            flag=\"hyperparameters\",\r\n            defaults=parameters,\r\n            poll_interval=1.0,\r\n        )\r\n\r\n    def tearDown(self):\r\n        \"\"\"Clean up temporary files.\"\"\"\r\n        import shutil\r\n        if os.path.exists(self.temp_dir):\r\n            shutil.rmtree(self.temp_dir)\r\n\r\n    def test_denylist_samples(self):\r\n        \"\"\"Test denylisting samples.\"\"\"\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        # Get first few sample IDs\r\n        denied_ids = set(wrapper.unique_ids[:3])\r\n\r\n        wrapper.denylist_samples(denied_ids)\r\n\r\n        # Check denied count was updated\r\n        self.assertEqual(wrapper.denied_sample_cnt, len(denied_ids))\r\n\r\n    def test_allowlist_samples(self):\r\n        \"\"\"Test allowlisting samples.\"\"\"\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        # First deny some samples\r\n        denied_ids = set(wrapper.unique_ids[:3])\r\n        wrapper.denylist_samples(denied_ids)\r\n        self.assertEqual(wrapper.denied_sample_cnt, len(denied_ids))\r\n\r\n        # Then allow them back\r\n        wrapper.allowlist_samples(denied_ids)\r\n\r\n        # If allow was successful, denied_sample_cnt should be updated\r\n        # (depends on mock behavior of get_df_view)\r\n\r\n    def test_denylist_clear(self):\r\n        \"\"\"Test clearing all denylists.\"\"\"\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        # Deny all samples\r\n        all_ids = set(wrapper.unique_ids)\r\n        wrapper.denylist_samples(all_ids)\r\n        self.assertEqual(wrapper.denied_sample_cnt, len(all_ids))\r\n\r\n        # Clear denials by passing None\r\n        wrapper.denylist_samples(None)\r\n        self.assertEqual(wrapper.denied_sample_cnt, 0)\r\n\r\n\r\nclass TestDataSampleTrackingWrapperStateDict(unittest.TestCase):\r\n    \"\"\"Test state_dict and load_state_dict functionality.\"\"\"\r\n\r\n    def setUp(self):\r\n        \"\"\"Create a temporary directory for logs.\"\"\"\r\n        self.temp_dir = tempfile.mkdtemp()\r\n        self.dataset = SimpleDataset(size=5)\r\n\r\n        # Initialize HP\r\n        parameters = {\r\n            'flush_interval': 3.0,\r\n            'flush_max_rows': 100,\r\n            'enable_h5': True,\r\n            'enable_flush': True\r\n        }\r\n        wl.watch_or_edit(\r\n            parameters,\r\n            flag=\"hyperparameters\",\r\n            defaults=parameters,\r\n            poll_interval=1.0,\r\n        )\r\n\r\n    def tearDown(self):\r\n        \"\"\"Clean up temporary files.\"\"\"\r\n        import shutil\r\n        if os.path.exists(self.temp_dir):\r\n            shutil.rmtree(self.temp_dir)\r\n\r\n    def test_state_dict_structure(self):\r\n        \"\"\"Test that state_dict has correct structure.\"\"\"\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        state = wrapper.state_dict()\r\n\r\n        # Check structure\r\n        self.assertIn(\"blockd_samples\", state)\r\n        self.assertIn(\"sample_statistics\", state)\r\n        self.assertIsInstance(state[\"blockd_samples\"], int)\r\n        self.assertIsInstance(state[\"sample_statistics\"], dict)\r\n\r\n\r\nclass TestDataSampleTrackingWrapperUtilities(unittest.TestCase):\r\n    \"\"\"Test utility methods.\"\"\"\r\n\r\n    def setUp(self):\r\n        \"\"\"Create a temporary directory for logs.\"\"\"\r\n        self.temp_dir = tempfile.mkdtemp()\r\n        self.dataset = SimpleDataset(size=10)\r\n\r\n        # Initialize HP\r\n        parameters = {\r\n            'flush_interval': 3.0,\r\n            'flush_max_rows': 100,\r\n            'enable_h5': True,\r\n            'enable_flush': True\r\n        }\r\n        wl.watch_or_edit(\r\n            parameters,\r\n            flag=\"hyperparameters\",\r\n            defaults=parameters,\r\n            poll_interval=1.0,\r\n        )\r\n\r\n    def tearDown(self):\r\n        \"\"\"Clean up temporary files.\"\"\"\r\n        import shutil\r\n        if os.path.exists(self.temp_dir):\r\n            shutil.rmtree(self.temp_dir)\r\n\r\n    def test_get_sample_id_at_index(self):\r\n        \"\"\"Test retrieving sample ID at given index.\"\"\"\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        # Get sample ID at index 0\r\n        sample_id = wrapper.get_sample_id_at_index(0)\r\n        self.assertEqual(sample_id, int(wrapper.unique_ids[0]))\r\n\r\n    def test_get_index_from_sample_id(self):\r\n        \"\"\"Test retrieving index from sample ID.\"\"\"\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        # Get index from first sample ID\r\n        sample_id = int(wrapper.unique_ids[0])\r\n        index = wrapper.get_index_from_sample_id(sample_id)\r\n        self.assertEqual(index, 0)\r\n\r\n    def test_infer_num_classes_from_dataset(self):\r\n        \"\"\"Test inferring number of classes from wrapped dataset.\"\"\"\r\n\r\n        # Create a dataset with num_classes attribute\r\n        dataset = SimpleDataset(size=10)\r\n        dataset.num_classes = 10\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        num_classes = wrapper.infer_num_classes()\r\n        self.assertEqual(num_classes, 10)\r\n\r\n    def test_infer_num_classes_binary_tags(self):\r\n        \"\"\"Test inferring num_classes with binary tag mapping.\"\"\"\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n            use_tags=True,\r\n            tags_mapping={\"target\": 1},\r\n        )\r\n\r\n        num_classes = wrapper.infer_num_classes()\r\n        self.assertEqual(num_classes, 2)\r\n\r\n\r\nclass TestDataSampleTrackingWrapperDuplicateDetection(unittest.TestCase):\r\n    \"\"\"Test duplicate sample detection and removal.\"\"\"\r\n\r\n    def setUp(self):\r\n        \"\"\"Create a temporary directory for logs.\"\"\"\r\n        self.temp_dir = tempfile.mkdtemp()\r\n\r\n        # Initialize HP\r\n        parameters = {\r\n            'flush_interval': 3.0,\r\n            'flush_max_rows': 100,\r\n            'enable_h5': True,\r\n            'enable_flush': True\r\n        }\r\n        wl.watch_or_edit(\r\n            parameters,\r\n            flag=\"hyperparameters\",\r\n            defaults=parameters,\r\n            poll_interval=1.0,\r\n        )\r\n\r\n    def tearDown(self):\r\n        \"\"\"Clean up temporary files.\"\"\"\r\n        import shutil\r\n        if os.path.exists(self.temp_dir):\r\n            shutil.rmtree(self.temp_dir)\r\n\r\n    @patch('weightslab.data.data_samples_with_ops.array_id_2bytes')\r\n    def test_duplicate_detection_with_hash(self, mock_hash):\r\n        \"\"\"Test that duplicate samples are detected and removed.\"\"\"\r\n\r\n        # Create dataset with duplicates\r\n        dataset = SimpleDataset(size=5)\r\n\r\n        # Mock hash function to create duplicates\r\n        # Return same hash for first two samples\r\n        hash_values = [100, 100, 101, 102, 103]\r\n        mock_hash.side_effect = hash_values\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=True,\r\n        )\r\n\r\n        # Should have removed one duplicate\r\n        # The wrapper should now have 4 unique samples instead of 5\r\n        # (though actual behavior depends on how Subset is used)\r\n        self.assertLessEqual(len(wrapper.unique_ids), len(dataset))\r\n\r\n\r\nclass TestDataSampleTrackingWrapperEquality(unittest.TestCase):\r\n    \"\"\"Test equality comparison.\"\"\"\r\n\r\n    def setUp(self):\r\n        \"\"\"Create a temporary directory for logs.\"\"\"\r\n        self.temp_dir = tempfile.mkdtemp()\r\n        self.dataset = SimpleDataset(size=10)\r\n\r\n        # Initialize HP\r\n        parameters = {\r\n            'flush_interval': 3.0,\r\n            'flush_max_rows': 100,\r\n            'enable_h5': True,\r\n            'enable_flush': True\r\n        }\r\n        wl.watch_or_edit(\r\n            parameters,\r\n            flag=\"hyperparameters\",\r\n            defaults=parameters,\r\n            poll_interval=1.0,\r\n        )\r\n\r\n    def tearDown(self):\r\n        \"\"\"Clean up temporary files.\"\"\"\r\n        import shutil\r\n        if os.path.exists(self.temp_dir):\r\n            shutil.rmtree(self.temp_dir)\r\n\r\n    def test_equality_same_wrapper(self):\r\n        \"\"\"Test equality comparison of wrappers.\"\"\"\r\n\r\n        wrapper1 = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        wrapper2 = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        # Both have same wrapped_dataset and same denied_count\r\n        self.assertTrue(wrapper1 == wrapper2)\r\n\r\n    def test_equality_different_types(self):\r\n        \"\"\"Test equality comparison with different types.\"\"\"\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        # Compare with non-wrapper object\r\n        self.assertFalse(wrapper == \"not a wrapper\")\r\n        self.assertFalse(wrapper == 123)\r\n\r\n\r\nclass TestDataSampleTrackingWrapperAsRecords(unittest.TestCase):\r\n    \"\"\"Test as_records functionality.\"\"\"\r\n\r\n    def setUp(self):\r\n        \"\"\"Create a temporary directory for logs.\"\"\"\r\n        self.temp_dir = tempfile.mkdtemp()\r\n        self.dataset = SimpleDataset(size=5)\r\n\r\n        # Initialize HP\r\n        parameters = {\r\n            'flush_interval': 3.0,\r\n            'flush_max_rows': 100,\r\n            'enable_h5': True,\r\n            'enable_flush': True\r\n        }\r\n        wl.watch_or_edit(\r\n            parameters,\r\n            flag=\"hyperparameters\",\r\n            defaults=parameters,\r\n            poll_interval=1.0,\r\n        )\r\n\r\n    def tearDown(self):\r\n        \"\"\"Clean up temporary files.\"\"\"\r\n        import shutil\r\n        if os.path.exists(self.temp_dir):\r\n            shutil.rmtree(self.temp_dir)\r\n\r\n    def test_as_records(self):\r\n        \"\"\"Test converting DataFrame to records.\"\"\"\r\n\r\n        wrapper = DataSampleTrackingWrapper(\r\n            wrapped_dataset=self.dataset,\r\n            root_log_dir=self.temp_dir,\r\n            enable_h5_persistence=False,\r\n            compute_hash=False,\r\n        )\r\n\r\n        records = wrapper.as_records()\r\n\r\n        self.assertIsInstance(records, list)\r\n        self.assertGreater(len(records), 0)\r\n        for record in records:\r\n            self.assertIsInstance(record, dict)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    unittest.main()\r\n"
        }
    ]
}