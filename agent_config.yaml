# Agent Configuration
agent:
  # Select the model provider.
  # Local: 'ollama'
  # Remote: 'openrouter', 'google', 'openai' (requires API tokens in .env)
  provider: openrouter
<<<<<<< HEAD

  # # Local Settings
  # ollama_model: qwen2.5:3b-instruct
  # fallback_to_local: true

  # Remote Model Selection
  openrouter_model: meta-llama/llama-3.1-8b-instruct:nitro
=======
  
  # Local Settings
  ollama_model: qwen2.5:3b-instruct
  fallback_to_local: true
  
  # Remote Model Selection
  openrouter_model: meta-llama/llama-3.3-70b-instruct #meta-llama/llama-3.1-8b-instruct:nitro #google/gemini-2.0-flash-lite-001 #google/gemini-2.0-flash-001 #mistralai/mistral-small-3.1-24b-instruct:free
>>>>>>> b8ea9963e094740bca9f18efbee9f65e9a720dc1
  google_model: gemini-1.5-flash
  openai_model: gpt-4o-mini
