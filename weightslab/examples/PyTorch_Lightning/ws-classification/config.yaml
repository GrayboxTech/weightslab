# Global configuration
device: auto
experiment_name: "mnist_lightning"

# Experiment config
max_epochs: 5

# PyTorch Lightning trainer configuration
# - Single GPU: set devices: 1 and strategy: auto
# - Multi GPU (single node): set devices: 2 (or more) and strategy: ddp
lightning:
  accelerator: auto
  devices: auto
  strategy: auto
  sync_batchnorm: false
  use_distributed_sampler: true

# Recommended presets (copy one block into `lightning` above)
lightning_presets:
  single_gpu:
    accelerator: gpu
    devices: 1
    strategy: auto
    sync_batchnorm: false
    use_distributed_sampler: false
  multi_gpu_ddp:
    accelerator: gpu
    devices: 2
    strategy: ddp
    sync_batchnorm: true
    use_distributed_sampler: true

# WeightsLab services
serving_grpc: true
serving_cli: true
serving_ui: false

# H5 persistence for fast data loading
enable_h5_persistence: true

# Start Training from scratch
is_training: false

# Data loaders configuration
data_root: ../datasets/mnist
data:
  train_loader:
    batch_size: 64
    shuffle: true
    num_workers: 4
  val_loader:
    batch_size: 64
    shuffle: false
    num_workers: 4

# Optimizer configuration
optimizer:
  lr: 0.001
